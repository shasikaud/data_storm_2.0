{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "data storm 2.0",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbXEOOILXSoO"
      },
      "source": [
        "Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ni8wtBh3UlP8"
      },
      "source": [
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import pandas as pd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pjPJFtQ4XXuy"
      },
      "source": [
        "Preparing dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DSqxCBaAWN8b"
      },
      "source": [
        "dataset = pd.read_csv('/content/drive/MyDrive/data_storm_2/new-set.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9b4z45aaZOnl"
      },
      "source": [
        "y = dataset.iloc[:,20].values\r\n",
        "cols = [0,20]   #drop id and checkin\r\n",
        "dataset.drop(dataset.columns[cols],axis=1,inplace=True)\r\n",
        "x = dataset.iloc[:,:].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w5pyYokC5QPW"
      },
      "source": [
        "y = np.where(y==\"Check-In\",1,y)     #encode\r\n",
        "y = np.where(y==\"Canceled\",2,y)\r\n",
        "y = np.where(y==\"No-Show\",3,y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGgQ7kF3hS4F"
      },
      "source": [
        "*Preprocessing - Date Conversion*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xbi3IPkJhVTl"
      },
      "source": [
        "booking = x[:,9]       #copy booking dates\r\n",
        "checkout = x[:,8]      #copy check-in dates\r\n",
        "checkin = x[:,7]       #copy check-out dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0TfSuNlfkek-"
      },
      "source": [
        "### func and class template to calculate the date difference between two given calendar dates\r\n",
        "### source : w3schools | added minor modifications\r\n",
        "\r\n",
        "class Date:\r\n",
        "    def __init__(self, d, m, y):\r\n",
        "        self.d = d\r\n",
        "        self.m = m\r\n",
        "        self.y = y\r\n",
        " \r\n",
        "monthDays = [31, 28, 31, 30, 31, 30,\r\n",
        "             31, 31, 30, 31, 30, 31]\r\n",
        " \r\n",
        "def countLeapYears(d):\r\n",
        "    years = d.y\r\n",
        "    if (d.m <= 2):\r\n",
        "        years -= 1\r\n",
        "    return int(years / 4) - int(years / 100) + int(years / 400)\r\n",
        " \r\n",
        "def getDifference(dt1, dt2): \r\n",
        "    n1 = dt1.y * 365 + dt1.d\r\n",
        "    for i in range(0, dt1.m - 1):\r\n",
        "        n1 += monthDays[i]\r\n",
        "    n1 += countLeapYears(dt1)\r\n",
        "    n2 = dt2.y * 365 + dt2.d\r\n",
        "    for i in range(0, dt2.m - 1):\r\n",
        "        n2 += monthDays[i]\r\n",
        "    n2 += countLeapYears(dt2)\r\n",
        "    return (n2 - n1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw0x0OvBhhuS"
      },
      "source": [
        "diff1 = [] #difference in days between booking and checkin\r\n",
        "diff2 = [] #difference in days between checkin and checkout\r\n",
        "month = [] #month of each booking to capture any seasonal variations\r\n",
        "\r\n",
        "for i in range(len(booking)):\r\n",
        "  arr1 = booking[i].split(\"/\")  #booking date\r\n",
        "  arr2 = checkin[i].split(\"/\")  #checkin date\r\n",
        "  arr3 = checkout[i].split(\"/\")  #checkout date\r\n",
        "  month.append(int(arr2[0]))   #stores month of each booking to capture any seasonal variations\r\n",
        "  dt1 = Date(int(arr1[1]), int(arr1[0]), int(arr1[2]))   #booking date\r\n",
        "  dt2 = Date(int(arr2[1]), int(arr2[0]), int(arr2[2]))   #checkin date\r\n",
        "  dt3 = Date(int(arr3[1]), int(arr3[0]), int(arr3[2]))   #checkout date\r\n",
        "  diff1.append(getDifference(dt1, dt2))   #difference in days between booking and checkin\r\n",
        "  diff2.append(getDifference(dt2, dt3))   #difference in days between checkin and checkout\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DnoSFLngrGjs"
      },
      "source": [
        "np_month = np.array(month).reshape(len(booking),1)   #reshaping np obj\r\n",
        "np_diff1 = np.array(diff1).reshape(len(booking),1)   #reshaping np obj\r\n",
        "np_diff2 = np.array(diff2).reshape(len(booking),1)   #reshaping np obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgDAAOvsi950"
      },
      "source": [
        "x = np.append(x, np_month, axis=1)    #append new column | month -> captures any seasonal variations that might affect bookings\r\n",
        "x = np.append(x, np_diff1, axis=1)    #append new column | difference in days between booking and checkin -> how well in advance does the user books\r\n",
        "x = np.append(x, np_diff2, axis=1)    #append new column | difference in days between checkin and checkout -> duration of stay planned by the user"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpyFN0-mvRd1"
      },
      "source": [
        "x = np.delete(x,7,axis=1)       #delete checkin date column\r\n",
        "x = np.delete(x,7,axis=1)       #delete checkout date column\r\n",
        "x = np.delete(x,7,axis=1)       #delete booking date column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "unpoYCif0AWF"
      },
      "source": [
        "Preprocessing - One Hot Encoding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rho_YtT1veSt"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j_GW1tkb1k7f"
      },
      "source": [
        "ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(), [0,2,3,4,5,6,10,11,12,13,14,15,16,19])], remainder='passthrough')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1B-R90_6HYL"
      },
      "source": [
        "x = ct.fit_transform(x)     #apply one hot label encoding to categorical data "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdWGHWWV7Yen"
      },
      "source": [
        "Splitting the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LiCkgFF6sf5"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.0001, random_state = 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KfLmdbUxAoLP"
      },
      "source": [
        "Feature Scaling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2FDtklTA-Xz"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "sc = StandardScaler()                             #apply feature scaling to remove bias from scalar values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6z5jCVfbGjF2"
      },
      "source": [
        "x_train[:, 50:] = sc.fit_transform(x_train[:, 50:])    #ignore the label encoded columns\r\n",
        "x_test[:, 50:] = sc.transform(x_test[:, 50:])          #use the same scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MsgG3MSJAxD"
      },
      "source": [
        "# **Classification model**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cTm6uRxtRMRq"
      },
      "source": [
        "Parameter Tuning"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cw23Pvg4rtbm"
      },
      "source": [
        "# #parameter tuning\r\n",
        "# from sklearn.model_selection import GridSearchCV \r\n",
        "  \r\n",
        "# defining parameter range \r\n",
        "param_grid = {'C': [0.1, 1, 10, 100, 1000],  \r\n",
        "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \r\n",
        "              'kernel': ['rbf']}  \r\n",
        "  \r\n",
        "grid = GridSearchCV(SVC(), param_grid, refit = True, verbose = 3) \r\n",
        "  \r\n",
        "# fitting the model for grid search \r\n",
        "grid.fit(x_train.astype(int), y_train.astype(int)) \r\n",
        "\r\n",
        "# print best parameter after tuning \r\n",
        "print(grid.best_params_) \r\n",
        "  \r\n",
        "# print how our model looks after hyper-parameter tuning \r\n",
        "print(grid.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebSyz9qRRRmI"
      },
      "source": [
        "Check on validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMEprTINRVKZ"
      },
      "source": [
        "## add code here to test on validation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5IYxAeizLWkz"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "--JYOouAJAXz",
        "outputId": "8eafa36b-044b-4e52-c083-dd37ee7070a5"
      },
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "classifier = LGBMClassifier()\n",
        "classifier.fit(x_train.astype(int), y_train.astype(int))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GaussianNB(priors=None, var_smoothing=1e-09)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CcHhD6m99YKD"
      },
      "source": [
        "# # print best parameter after tuning \r\n",
        "# print(grid.best_params_) \r\n",
        "  \r\n",
        "# # print how our model looks after hyper-parameter tuning \r\n",
        "# print(grid.best_estimator_) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EhkpY95HLaCB"
      },
      "source": [
        "Prediction on train data set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bh27CpwJIrY3"
      },
      "source": [
        "y_pred = classifier.predict(x_test)     #predict on the test set of the training data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-05MBQZuNASl"
      },
      "source": [
        "Confusion Matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYCG5tdoM1Kr",
        "outputId": "04492962-1df9-4b09-9e39-0e91089f69b8"
      },
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\r\n",
        "print(confusion_matrix(y_test.astype(int), y_pred.astype(int)))\r\n",
        "print(classification_report(y_test.astype(int), y_pred.astype(int)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[4]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           1       1.00      1.00      1.00         4\n",
            "\n",
            "    accuracy                           1.00         4\n",
            "   macro avg       1.00      1.00      1.00         4\n",
            "weighted avg       1.00      1.00      1.00         4\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BxbtaoObRVGC"
      },
      "source": [
        "## Test on the validation set / new dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "algpawcwNW3B"
      },
      "source": [
        "#test set\n",
        "#testset = pd.read_csv('/content/drive/MyDrive/data_storm_2/Hotel-A-test.csv') \n",
        "#validation set\n",
        "testset = pd.read_csv('/content/drive/MyDrive/data_storm_2/Hotel-A-validation.csv')      "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxLSg7BmR5UI"
      },
      "source": [
        "z = testset.iloc[:,1:].values        #remove first column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HEezQMKSV0a"
      },
      "source": [
        "booking = z[:,9]           #copy bookin dates\r\n",
        "checkout = z[:,8]          #copy checkout dates\r\n",
        "checkin = z[:,7]           #copy checkin dates"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WUiteTO8Sr8x"
      },
      "source": [
        "diff1 = [] #stores difference in days between booking and checkin\r\n",
        "diff2 = [] #stores difference in days between checkin and checkout\r\n",
        "month = [] #stores month of each booking to capture any seasonal variations\r\n",
        "\r\n",
        "for i in range(len(booking)):\r\n",
        "  arr1 = booking[i].split(\"/\")  #booking date\r\n",
        "  arr2 = checkin[i].split(\"/\")  #checkin date\r\n",
        "  arr3 = checkout[i].split(\"/\")  #checkout date\r\n",
        "  month.append(int(arr2[0]))   #stores month of each booking to capture any seasonal variations\r\n",
        "  dt1 = Date(int(arr1[1]), int(arr1[0]), int(arr1[2]))   #booking date\r\n",
        "  dt2 = Date(int(arr2[1]), int(arr2[0]), int(arr2[2]))   #checkin date\r\n",
        "  dt3 = Date(int(arr3[1]), int(arr3[0]), int(arr3[2]))   #checkout date\r\n",
        "  diff1.append(getDifference(dt1, dt2))   #day difference between booking and checkin\r\n",
        "  diff2.append(getDifference(dt2, dt3))   #day difference between checkin and checkout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXShuPRoS4Vo"
      },
      "source": [
        "np_month = np.array(month).reshape(len(booking),1)   #reshaping np obj\r\n",
        "np_diff1 = np.array(diff1).reshape(len(booking),1)   #reshaping np obj\r\n",
        "np_diff2 = np.array(diff2).reshape(len(booking),1)   #reshaping np obj"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IPK-5LlpS9r8"
      },
      "source": [
        "z = np.append(z, np_month, axis=1)    #append new column | month of checkin -> to capture seasonal variations\r\n",
        "z = np.append(z,np_diff1, axis=1)     #append new column  | duration of prior booking before checkin\r\n",
        "z = np.append(z, np_diff2, axis=1)    #append new column | duration of hotel stay i.e. difference between checkin vs checkout"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wj55wMATFxo"
      },
      "source": [
        "z = np.delete(z,7,axis=1)       #delete checkin column\r\n",
        "z = np.delete(z,7,axis=1)       #delete checkout column\r\n",
        "z = np.delete(z,7,axis=1)       #delete bookin column"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qgpiEZJ2Tefq"
      },
      "source": [
        "#ct = ColumnTransformer(transformers=[('encoder',OneHotEncoder(), [0,2,3,4,5,6,10,11,12,13,14,15,16,19])], remainder='passthrough')\r\n",
        "z = ct.transform(z)      #hot encode lable the categorical data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RW3e8PSeTuuH"
      },
      "source": [
        "z[:, 50:] = sc.transform(z[:, 50:])       #use the same scaler"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aGyDONGQV7HS"
      },
      "source": [
        "y_pred = classifier.predict(z)            #predict for the test set using the trained classifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8rpT5aLWAju",
        "outputId": "30c9472f-5b66-4243-c1e0-c149258c5af8"
      },
      "source": [
        "import csv                                  #write out to a csv file\r\n",
        "with open('results.csv', 'w', newline='') as file:\r\n",
        "    writer = csv.writer(file)\r\n",
        "    results = []\r\n",
        "    for i in y_pred:\r\n",
        "      writer.writerow([i])\r\n",
        "      if i not in results:\r\n",
        "        results.append(i)\r\n",
        "        print (i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n",
            "2\n",
            "3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tyJWsLxFWD8R"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}